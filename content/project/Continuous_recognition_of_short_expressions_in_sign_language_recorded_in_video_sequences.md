+++
# Date this page was created.
date = 2016-04-27T00:00:00

# Project title.
title = "Reconocimiento continuo de expresiones cortas en el lenguaje de señas registrado en secuencias de vídeo."

# Project summary to display on homepage.
summary = "Affiliated Entity:[**Universidad Industrial de Santander**](https://www.uis.edu.co/webUIS/es/index.jsp) - _Current stage_: **Selección de videos que registran gestos continuos**"

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "bubbles.jpg"

# Tags: can be used for filtering projects.
# Example: `tags = ["slr"]`
tags = ["Continuos Sign Language Recognition"]

# Optional external URL for project (replaces project detail page).
external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "headers/bubbles-wide.jpg"


+++
**Summary:**  
La comunidad de sordomudos y personas con alguna limitación auditiva se estima en
360 millones de personas a nivel mundial, según el reporte oficial de la organización
mundial de la salud (OMS). En Colombia, para el 2016 se reportó una comunidad de
596.814 personas con alguna limitación auditiva. Esta comunidad ha logrado
establecer un lenguaje estructurado que se basa principalmente en movimientos
articulares de los miembros superiores junto con expresiones faciales, cuyo desarrollo
ha permitido la interacción y comunicación entre sus integrantes. Sin embargo, la
interacción con otras comunidades persiste hoy en día como un problema de inclusión
social que limita su integración en diversos escenarios.
A pesar de los avances en reconocimiento de gestos y caracterización de movimientos
articulados, existe un número limitado de herramientas tecnológicas que permiten la
interpretación de estos lenguajes para la comunicación eficiente entre comunidades o el
fácil acceso a programas de enseñanza. Además, la caracterización automática de
gestos enfrenta grandes desafíos en cuanto a la variabilidad de los movimientos y
sentencias gramaticales desarrolladas. Tal factor es inter e intrapersonal por la
variabilidad natural de los gestos humanos y diversos factores externos, por ejemplo:
los ambientes donde se desarrollan las señas y las características culturales y
regionales de cada comunidad. En este sentido, las actuales propuestas para el
reconocimiento de gestos en el lenguaje de señas están enfocadas tanto en análisis
globales como locales, realizando segmentaciones totales de los
articuladores y utilizando representaciones de puntos de interés para capturar
información local. Por otro lado, un problema de interés con complejidad adicional es el
reconocimiento continuo de gestos o expresiones cortas. Su dificultad radica en
relacionar los gestos que componen cada expresión, los cuales tienen coherencia
temporal y gramatical. Nuevos enfoques que trabajan este desafío se basan en
métodos estadísticos que modelan cada seña.
La presente propuesta busca desarrollar una estrategia computacional para el
reconocimiento continuo de señas registradas en vídeos, teniendo en cuenta tanto la
variabilidad local de cada gesto como la variación a lo largo de su descripción
gramatical. El proceso se inicia capturando secuencias de videos que registran
diferentes sentencias gramaticales en el lenguaje. Estas secuencias serán analizadas
para determinar las características espacio-temporales que permitan una apropiada
representación de los gestos durante el video. Una vez los gestos son caracterizados
localmente, se desarrollarán métodos que permitan capturar la coherencia temporal de
los gestos para reconocer frases cortas. El modelo de caracterización continuo será
mapeado a un algoritmo de aprendizaje de máquina, previamente entrenado, para
obtener una clasificación automática de las señas.  
  
**Objetive:**  
Proponer un método computacional para el reconocimiento continuo de gestos
en el lenguaje de señas registrado en video.
  
Affiliated Entity: 
[**Universidad Industrial de Santander**](https://www.uis.edu.co/webUIS/es/index.jsp)  
Status: **Active**  
Initial date: September 2018  
Final date: December 2019  
Current stage: **Selección de videos que registran gestos continuos**

